{"metadata":{"colab":{"provenance":[],"collapsed_sections":["DgazpHvU-CVM","PbOr70Rl7eOv","LVNBRsmvgSRY"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9988,"databundleVersionId":868324,"sourceType":"competition"}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Airbus Ship Detection","metadata":{"id":"uS_shSxhBpJy"}},{"cell_type":"code","source":"import os\nimport random\nimport math\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom skimage.io import imread\nfrom sklearn.model_selection import train_test_split\n#from skimage.morphology import label\nfrom tqdm import tqdm\n\n\n# Define the constants\nDATASET_PATH = \"/kaggle/input/airbus-ship-detection\"\nTRAIN_FOLDER = os.path.join(DATASET_PATH, \"train_v2\")\nTEST_FOLDER = os.path.join(DATASET_PATH, \"test_v2\")\nCSV_PATH = os.path.join(DATASET_PATH, \"train_ship_segmentations_v2.csv\")\n\n# Style the plots and display them inline\nplt.style.use(\"fivethirtyeight\")\n%matplotlib inline","metadata":{"id":"BLPfw-8MBocG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define some helper functions for RLE encoding and decoding,\n# which will be used later for converting\n# the predicted ship masks to the required format\n\ndef multi_rle_encode(img):\n    labels = label(img[:, :, 0])\n    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    Convert run-length encoded mask to a binary mask\n\n    Args:\n        mask_rle (str): Run-length encoded mask string\n        shape (tuple): Shape of the output binary mask\n\n    Returns:\n        numpy.ndarray: Binary mask array\n    '''\n    # Split the run-length encoded string\n    s = mask_rle.split()\n    starts = np.asarray(s[0:][::2], dtype=int) - 1\n    lengths = np.asarray(s[1:][::2], dtype=int)\n    ends = starts + lengths\n\n    # Initialize an array for the binary mask\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n\n    # Set the pixels corresponding to the mask region to 1\n    for start, end in zip(starts, ends):\n        img[start:end] = 1\n\n    # Reshape the array to the desired shape\n    return img.reshape(shape).T\n\n\ndef masks_as_image(in_mask_list, dim = (768, 768)):\n    '''\n    Combine individual ship masks into a single mask array\n\n    Args:\n        in_mask_list (list): List of ship masks (run-length encoded strings)\n\n    Returns:\n        numpy.ndarray: Combined mask array\n    '''\n    # Initialize an array to hold the combined mask\n    all_masks = np.zeros(dim, dtype=np.int16)\n\n    # Iterate over the ship masks and add them to the combined mask\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks += rle_decode(mask)\n\n    # Expand dimensions to match the expected shape\n    return np.expand_dims(all_masks, -1)","metadata":{"id":"skXv1jn0Hhl8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to view a random image from the training set\ndef view_random_image(target_dir):\n  '''\n  View a random image from the specified directory\n\n  Args:\n      target_dir (str): Path to the directory containing images\n\n  Returns:\n      numpy.ndarray: Image array\n  '''\n  # Get a random image path\n  random_image = random.sample(os.listdir(target_dir), 1)\n\n  # Read in the image and plot it\n  img = mpimg.imread(target_dir + \"/\" + random_image[0])\n  plt.imshow(img)\n  plt.axis(\"off\")\n\n  # Print the shape of the image\n  print(f\"Image shape: {img.shape}\")\n\n  return img\n","metadata":{"id":"T_PuxtPjDL3T","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"TV6VeYU-7VP8"}},{"cell_type":"code","source":"import os\n\nfor dirpath, dirnames, filenames in os.walk(DATASET_PATH):\n  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","metadata":{"id":"FOX00pF953Nu","outputId":"6eed664f-bce4-4272-9708-9b51d8bce8f0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(CSV_PATH)\ndf.head()","metadata":{"id":"UaJVd3ZJBXuY","outputId":"ff8ba91e-9054-4f9d-9523-ec1ba7f04591","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = view_random_image(TRAIN_FOLDER)","metadata":{"id":"FV1u5tn_DWT9","outputId":"f8253879-947d-4459-9af9-31af6d6ef7cc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_images = len(df['ImageId'].unique())\nprint(f\"The number of images in the dataset: {num_images}\")","metadata":{"id":"U2KY2JF1DgOy","outputId":"346737c0-22a4-4ace-881a-338fe253480e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_ships = len(df[df['EncodedPixels'].notna()])\nnum_non_ships = num_images - num_ships\nprint('Number of ships:', num_ships)\nprint('Number of non-ships:', num_non_ships)","metadata":{"id":"-A6hpqeaDjem","outputId":"d7b3529e-0662-436a-8e5b-2b562983352f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot a bar chart of the ship vs. non-ship distribution\nplt.figure(figsize=(10, 6))\nplt.bar(['Ships', 'Non-Ships'], [num_ships, num_non_ships])\nplt.xlabel('Category')\nplt.ylabel('Count')\nplt.title('Ship vs. Non-Ship')\nplt.show()","metadata":{"id":"DdgoUMAeDnJV","outputId":"157e59c0-fd27-4f99-c1de-c1107956dfb8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_of_masks_counts = df[\"ImageId\"].value_counts()\nnumber_of_masks_counts","metadata":{"id":"rzS7QI0zDrGK","outputId":"f9f16394-d6ed-4a77-877f-1dcdddb58bac","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a copy of the working dataframe\nship_df = df.copy()\nship_df['NumberOfShips'] = ship_df['EncodedPixels'].notnull().astype(int)\nship_df['EncodedPixels'] = ship_df['EncodedPixels'].replace(0, '')\nship_df","metadata":{"id":"WnXb9p5HD7lx","outputId":"6b47afaa-15c1-4bd4-9033-a8a8260c3f4b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group by the image name\nship_df = ship_df.groupby('ImageId').sum().reset_index()\nship_df","metadata":{"id":"5ky4qR9QEGhd","outputId":"0aa83322-ec57-47a0-ac9d-fa3e287ec5e4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot a histogram\nplt.figure(figsize=(10, 6))\nplt.hist(number_of_masks_counts, bins=10)  # Create a histogram with 30 bins\nplt.title(\"Number of separate masks per image\")\nplt.xlabel(\"Count\")\nplt.ylabel(\"Frequency\")\nplt.show()","metadata":{"id":"kb2J32J8F_PP","outputId":"64d21ff3-247b-4815-a0e3-6e95237d7343","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Working with NaNs","metadata":{"id":"gdMgB36yHCE_"}},{"cell_type":"code","source":"rle_with_zeros = rle_encode(np.zeros((768, 768, 1)))\nprint(rle_with_zeros == \"\")","metadata":{"id":"jzXIbVkDHC1x","outputId":"b286f7db-7d2a-44bf-ad93-26bac3825540","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.fillna(\"\")\ndf.head()","metadata":{"id":"BtiY2zerJZHF","outputId":"e2bc7f08-d284-4add-d826-a450a0791f36","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Undersampling negative samples","metadata":{"id":"ujBAmArJJy80"}},{"cell_type":"code","source":"ship_df['NumberOfShips'].plot.hist()","metadata":{"id":"3JCc8UDjKDdI","outputId":"f561033d-feb3-4704-8f99-385baa6c9c7e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ship_df['NumberOfShips'].value_counts()","metadata":{"id":"aOMjC34uJkyt","outputId":"09713b05-e10b-4d44-97b7-1517f2a38396","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ships, valid_ships = train_test_split(ship_df,\n                                            test_size = 0.2,\n                                            stratify = ship_df['NumberOfShips'])","metadata":{"id":"rpnGjVQfMr8G","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ships","metadata":{"id":"8SkmkEJSf-p8","outputId":"3e81c6cb-9a49-4d45-d925-a58bd4a023a8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_ships","metadata":{"id":"pDGPeJVIgCJ5","outputId":"09ab77a5-abb6-400e-f412-3ee97ab9e89e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def undersample_zeros(df, n):\n    zeros = df[df['NumberOfShips'] == 0].sample(n=n)\n    nonzeros = df[df['NumberOfShips'] != 0]\n    return pd.concat((nonzeros, zeros))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PERCENTAGE_WITHOUT_SHIPS = 0.2\ntrain_ships = undersample_zeros(train_ships, int(len(train_ships) * PERCENTAGE_WITHOUT_SHIPS))\nvalid_ships = undersample_zeros(valid_ships, int(len(valid_ships) * PERCENTAGE_WITHOUT_SHIPS))\ntrain_ships['NumberOfShips'].plot.hist(bins=np.arange(10))","metadata":{"id":"tAZangEMMwYe","outputId":"cb044759-d6fd-4fb3-d1d0-70b6576d8d01","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_ships['NumberOfShips'] > 0).astype(int).value_counts().plot.bar()","metadata":{"id":"OmJJRpG7NDN7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(valid_ships['NumberOfShips'] > 0).astype(int).value_counts().plot.bar()","metadata":{"id":"1sOzyZKRNEPq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show(image, mask):\n    print(image.shape)\n    print(mask.shape)\n    # Set up the matplotlib figure\n    plt.figure(figsize=(12, 6))\n\n    # Display ground truth mask\n    plt.subplot(1, 2, 1)\n    plt.imshow(mask, cmap='gray')\n    plt.title('Ground Truth Mask')\n    plt.axis('off')\n\n    # Display BGR image\n    plt.subplot(1, 2, 2)\n    plt.imshow(image)\n    plt.title('Image')\n    plt.axis('off')\n\n    # Show the plot\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\nimage_name = np.random.choice(np.array(train_ships['ImageId']))\nimage_path = os.path.join(TRAIN_FOLDER, image_name)\nimage = cv2.imread(image_path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nmask = masks_as_image(df[df['ImageId'] == image_name]['EncodedPixels'])\nshow(image, mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Unet + Mix Vision Transformer","metadata":{"id":"EAaMASk8UvpG"}},{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/segmentation_models.pytorch","metadata":{"id":"WbwEn7nfNYsX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\n\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\nimport segmentation_models_pytorch as smp\nfrom segmentation_models_pytorch import utils\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset as BaseDataset\n\ntrain_dim = (544, 544)\n\nENCODER = 'mit_b0'\nENCODER_WEIGHTS = 'imagenet'\nCLASSES = ['ship']\nACTIVATION = 'sigmoid'\nDEVICE = 'cuda'\nBATCH_SIZE = 16","metadata":{"id":"S549pUdKlfre","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as albu\n\n\ndef get_training_augmentation():\n    train_transform = [\n        albu.HorizontalFlip(p=0.5),\n        albu.VerticalFlip(p=0.5),\n    ]\n    return albu.Compose(train_transform)\n\n\ndef get_validation_augmentation():\n    test_transform = [\n        #albu.PadIfNeeded(384, 480)\n    ]\n    return albu.Compose(test_transform)\n\n\ndef to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1).astype('float32')\n\n\ndef get_preprocessing(preprocessing_fn):\n    \"\"\"Construct preprocessing transform\n\n    Args:\n        preprocessing_fn (callbale): data normalization function\n            (can be specific for each pretrained neural network)\n    Return:\n        transform: albumentations.Compose\n\n    \"\"\"\n\n    _transform = [\n        albu.Lambda(image=preprocessing_fn),\n        albu.Lambda(image=to_tensor, mask=to_tensor),\n    ]\n    return albu.Compose(_transform)\n\n\n# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()","metadata":{"id":"-knHjDFRlcRf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(BaseDataset):\n\n    CLASSES = ['ship']\n\n    def __init__(\n            self,\n            images_set,\n            masks_set,\n            train_dim,\n            augmentation=None,\n            preprocessing=None\n    ):\n        self.images = images_set\n        self.masks = masks_set\n        self.class_values = [1]\n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n        self.train_dim = train_dim\n\n    def __getitem__(self, i):\n        image_path = os.path.join(TRAIN_FOLDER, self.images[i])\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = masks_as_image(self.masks[self.masks['ImageId'] == self.images[i]]['EncodedPixels'])\n\n        image = cv2.resize(image, self.train_dim, interpolation = cv2.INTER_AREA)\n        mask = cv2.resize(mask, self.train_dim, interpolation = cv2.INTER_AREA)\n\n        masks = [(mask == v) for v in self.class_values]\n        mask = np.stack(masks, axis=-1).astype('float')\n\n        # apply augmentations\n        if self.augmentation:\n            sample = self.augmentation(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n\n        # apply preprocessing\n        if self.preprocessing:\n            sample = self.preprocessing(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n\n        return image, mask\n\n    def __len__(self):\n        return len(self.images)","metadata":{"id":"N9IcB3EJVMOB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create segmentation model with pretrained encoder\nmodel = smp.Unet(\n    encoder_name=ENCODER,\n    encoder_weights=ENCODER_WEIGHTS,\n    classes=len(CLASSES),\n    activation=ACTIVATION,\n)\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","metadata":{"id":"TUWEv5W1l5jN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(\n    np.array(train_ships['ImageId']),\n    df,\n    train_dim,\n    augmentation=get_training_augmentation(),\n    preprocessing=get_preprocessing(preprocessing_fn),\n)\n\nvalid_dataset = Dataset(\n    np.array(valid_ships['ImageId']),\n    df,\n    train_dim,\n    augmentation=get_validation_augmentation(),\n    preprocessing=get_preprocessing(preprocessing_fn),\n)","metadata":{"id":"A-h8sZbQmBCi","outputId":"d1d4e49f-6efa-42e5-8222-62adf52256e2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = smp.utils.losses.DiceLoss()\nmetrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n]\n\noptimizer = torch.optim.Adam([\n    dict(params=model.parameters(), lr=0.0001),\n])","metadata":{"id":"UBwPjhMRmJYu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_epoch = smp.utils.train.TrainEpoch(\n    model,\n    loss=loss,\n    metrics=metrics,\n    optimizer=optimizer,\n    device=DEVICE,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    model,\n    loss=loss,\n    metrics=metrics,\n    device=DEVICE,\n    verbose=True,\n)","metadata":{"id":"MhkcFq1_l6m9","outputId":"2f92cfc1-0e84-4dd6-ffa5-c11e0a9c3e66","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_score = 0\nEPOCHS = 1\nweights_dir = \"weights\"\nos.makedirs(weights_dir, exist_ok=True)\n\nfor epoch in range(0, EPOCHS):\n\n    print(f'Epoch: {epoch}')\n    train_logs = train_epoch.run(train_loader)\n    valid_logs = valid_epoch.run(valid_loader)\n\n    if max_score < valid_logs['iou_score']:\n        max_score = valid_logs['iou_score']\n        torch.save(model, os.path.join(weights_dir, f\"{ENCODER}_{epoch}_epoch.pth\"))\n        print('Model saved!')\n\n    if epoch == EPOCHS - 10:\n        optimizer.param_groups[0]['lr'] = 1e-5\n        print('Decrease decoder learning rate to 1e-5!')","metadata":{"id":"hxef8TDGmMhA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing trained model","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport glob\nimport random\n\nimport cv2\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport segmentation_models_pytorch as smp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ShipSegmentation:\n\n    def __init__(self, model_path, device, encoder='mit_b0', encoder_weights='imagenet'):\n        self.device = device\n        self._model = self._load_model(model_path)\n        self._encoder = encoder\n        self._encoder_weights = encoder_weights\n        preprocessing_fn = smp.encoders.get_preprocessing_fn(self._encoder, self._encoder_weights)\n        self.model_preprocessing = self._get_preprocessing(preprocessing_fn)\n\n    def _load_model(self, model_path):\n        model = torch.load(model_path, map_location=self.device)\n        model.to(self.device)\n        model.eval()\n        return model\n\n\n    def _to_tensor(self, x):\n        return x.transpose(2, 0, 1).astype('float32')\n\n    def _get_preprocessing(self, preprocessing_fn):\n        _transform = [\n            transforms.Lambda(lambda x: preprocessing_fn(x)),\n            transforms.Lambda(lambda x: self._to_tensor(x)),\n        ]\n        return transforms.Compose(_transform)\n    \n    def preprocessing(self, image):\n        dim = (544, 544)\n        image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n        image = self.model_preprocessing(image)\n        return torch.from_numpy(image).to(self.device).unsqueeze(0)\n    \n    def predict(self, orig_image):\n        image = self.preprocessing(orig_image)\n        ship_mask = self._model.predict(image)\n        ship_mask = (ship_mask.squeeze().cpu().numpy().round() * 255).astype(np.uint8)\n        ship_mask = cv2.resize(ship_mask, orig_image.shape[:2][::-1], interpolation = cv2.INTER_AREA)\n        return ship_mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show(rgb_image, predicted_mask):\n    # Set up the matplotlib figure\n    plt.figure(figsize=(12, 6))\n\n    # Display RGB image\n    plt.subplot(1, 2, 1)\n    plt.imshow(rgb_image)\n    plt.title('Image')\n    plt.axis('off')\n\n    # Display predicted mask\n    plt.subplot(1, 2, 2)\n    plt.imshow(predicted_mask, cmap='gray')\n    plt.title('Predicted Mask')\n    plt.axis('off')\n\n    # Show the plot\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_dir = \"weights\"\nmodel_path = os.path.join(weights_dir, \"mit_b0_18_epoch.pth\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nship = ShipSegmentation(model_path=model_path, device=device)\n\nimages = glob.glob(os.path.join(TEST_FOLDER, \"*\"))\nimage_path = random.choice(images)\n\nbgr_image = cv2.imread(image_path)\nrgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n\npredicted_mask = ship.predict(rgb_image)\npredicted_mask = cv2.cvtColor(predicted_mask, cv2.COLOR_GRAY2BGR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}